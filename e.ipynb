{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# Create a spaCy parser\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "class BagOfWords(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        results = []\n",
    "        for document in X:\n",
    "            row = {}\n",
    "            for word in list(nlp(document, tag=False, parse=False, entity=False)):\n",
    "                if len(word.text.strip()):\n",
    "                    row[word.text] = True\n",
    "            results.append(row)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_filename = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"python_tweets.json\")\n",
    "labels_filename = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"python_classes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[918790128952156160, 918790062313111552, 918790054713192455, 918790045355491328, 918790009909628928, 918790003529981953, 918789986941407232, 918789968281161729, 918789963734503430, 918789927353114624, 918789888958500864, 918789850328731648, 918789848504393728, 918789845111267331, 918789825888583686, 918789783379464193, 918789759522279424, 918789751393669120, 918789748440879104, 918789739125268480, 918789737590161408, 918789674122076160, 918789654698217472, 918789654127759360, 918789649753169920, 918789633613410304, 918789628735475712, 918789563937710082, 918789505905291264, 918789504324038656, 918789446216151040, 918789421000024064, 918789420194578432, 918789398396915713, 918789365790277632, 918789358739652608, 918789340028747778, 918789337407467521, 918789336182677504, 918789334945366017, 918789318990327808, 918789308005351426, 918789271607275520, 918789260945305600, 918789232319258625, 918789207010799616, 918789206113243136, 918789194931228672, 918789167835992066, 918789139411107840, 918789113914036224, 918789113356128256, 918789086302916608, 918789068309323776, 918789023031808001, 918789003532320768, 918788946733289472, 918788945386856448, 918788821273202688, 918788803506130944, 918788788167507968, 918788771495194624, 918788758979440640, 918788756533997568, 918788750628532225, 918788738838355969, 918788724275675136, 918788720660115456, 918788717803958273, 918788717711564800, 918788680722124800, 918788658542596097, 918788655648354305, 918788621813125120, 918788596995448832, 918788566116732929, 918788557317263360, 918788545640361984, 918788535095906304, 918788512224305153, 918788473749827584, 918788469757005824, 918788451436302336, 918788432780029952, 918788428808024066, 918788420251484160, 918788415755309057, 918788386038669312, 918788372906364928, 918788364723212288, 918788253867827206, 918788176680022018, 918788171327881218, 918788169415430145, 918788153577701376, 918788134468452352, 918788118077231104, 918788118030958592, 918788092810727424, 918788042390990849, 918818500415700993, 918818469931388928, 918818457503830021, 918818455654141953, 918818380550782982, 918818322799648768, 918818306135592960, 918818284908113923, 918818268072300544, 918818261441097728, 918818241006333953, 918818227924242432, 918818203756875776, 918818173603913728, 918818116876034048, 918817967407689728, 918817850684559360, 918817846800547842, 918817824960901120, 918817749714968580, 918817740592381952, 918817740432998400, 918817733432590337, 918817711374745600, 918817694228668416, 918817673454260225, 918817650226221057, 918817649907380231, 918817649366372352, 918817648833527808, 918817642525413378, 918817641539579904, 918817607247106048, 918817606576066560, 918817545976721408, 918817524342579200, 918817494869176320, 918817489370394624, 918817468524777472, 918817427244195840, 918817395866816512, 918817376224890880, 918817361830006786, 918817348366290944, 918817346130710529, 918817341265264640, 918817333874917376, 918817296486776832, 918817292812738560, 918817279512662016, 918817259216351233, 918817235430391808, 918817164517404672, 918817109098074113, 918817107160297472, 918817094719782913, 918817092534657024, 918816991418437633, 918816981490561024, 918816959843536896, 918816951866155011, 918816918571765760, 918816849210441728, 918816841610358784, 918816807422775297, 918816805598191621, 918816805031960577, 918816805027766272, 918816801634639872, 918816771838304257, 918816736996200448, 918816736362811393, 918816616586141696, 918816611217412096, 918816594637271042, 918816592552714240, 918816544964186112, 918816489553252352, 918816431168466944, 918816400273059840, 918816396993327104, 918816360414707712, 918816295898017792, 918816281679319040, 918816256874119168, 918816251652210689, 918816245205602304, 918816242319929344, 918816197386428416, 918816183855538176, 918816182769274880, 918816180583968769, 918816158228369408, 918816158198980608, 918816142310785024, 918816118873182208, 918816112183267330, 918816106911027201, 918816079119568897, 918816078431703040, 918819552380665856, 918819449909760001, 918819388232364032, 918819335719792640, 918819313318088705, 918819277985275909, 918819192744296448, 918819190370381824, 918819134498066433, 918819102596190208, 918819087853035520, 918818974640607232, 918818964637126658, 918818963240488960, 918818924724129797, 918818917446860801, 918818764761726976, 918818743119048704, 918818656397783040, 918818599279607808, 918818592719646720, 918818567235219456, 918818567142985728, 918818505117462528, 918818500415700993, 918818469931388928, 918818457503830021, 918818455654141953, 918818380550782982, 918818322799648768, 918818306135592960, 918818284908113923, 918818268072300544, 918818261441097728, 918818241006333953, 918818227924242432, 918818203756875776, 918818173603913728, 918818116876034048, 918817967407689728, 918817850684559360, 918817846800547842, 918817824960901120, 918817749714968580, 918817740592381952, 918817740432998400, 918817733432590337, 918817711374745600, 918817694228668416, 918817673454260225, 918817650226221057, 918817649907380231, 918817649366372352, 918817648833527808, 918817642525413378, 918817641539579904, 918817607247106048, 918817606576066560, 918817545976721408, 918817524342579200, 918817494869176320, 918817489370394624, 918817468524777472, 918817427244195840, 918817395866816512, 918817376224890880, 918817361830006786, 918817348366290944, 918817346130710529, 918817341265264640, 918817333874917376, 918817296486776832, 918817292812738560, 918817279512662016, 918817259216351233, 918817235430391808, 918817164517404672, 918817109098074113, 918817107160297472, 918817094719782913, 918817092534657024, 918816991418437633, 918816981490561024, 918816959843536896, 918816951866155011, 918816918571765760, 918816849210441728, 918816841610358784, 918816807422775297, 918816805598191621, 918816805031960577, 918816805027766272, 918816801634639872, 918816771838304257, 918816736996200448, 918816736362811393, 918816616586141696, 918816611217412096, 918816594637271042, 918816592552714240, 918820752257896448, 918820748176822273, 918820740970971136, 918820739888959488, 918820651842048000, 918820621139582976, 918820620951085056, 918820619642425344, 918820615552884736, 918820615087382528, 918820584955490304, 918820558908854272, 918820491359670272, 918820450586824704, 918820443842326529, 918820389496778752, 918820299688239104, 918820291610120192, 918820259821363201, 918820226581512192, 918820220604747776, 918820194772045824, 918820129970016261, 918820128740999168, 918820127583408129, 918820126274748417, 918820124836155393, 918820123477147648, 918820122227281920, 918820120780304384, 918820118838341632, 918820117450027008, 918820116036546560, 918820077599895552, 918820066560544769, 918820010675593217, 918820005323689984, 918819958125146115, 918819885098131457, 918819877921673216, 918819790617112577, 918819741518782465, 918819734728200192, 918819664758804482, 918819628582887424, 918819611679838208, 918819610597756929, 918819552380665856, 918819449909760001, 918819388232364032, 918819335719792640, 918819313318088705, 918819277985275909, 918819192744296448, 918819190370381824, 918819134498066433, 918819102596190208, 918819087853035520, 918818974640607232, 918818964637126658, 918818963240488960, 918818924724129797, 918818917446860801, 918818764761726976, 918818743119048704, 918818656397783040, 918818599279607808, 918818592719646720, 918818567235219456, 918818567142985728, 918818505117462528, 918818500415700993, 918818469931388928, 918818457503830021, 918818455654141953, 918818380550782982, 918818322799648768, 918818306135592960, 918818284908113923, 918818268072300544, 918818261441097728, 918818241006333953, 918818227924242432, 918818203756875776, 918818173603913728, 918818116876034048, 918817967407689728, 918817850684559360, 918817846800547842, 918817824960901120, 918817749714968580, 918817740592381952, 918817740432998400, 918817733432590337, 918817711374745600, 918817694228668416, 918817673454260225, 918817650226221057, 918817649907380231, 918817649366372352]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tweets = []\n",
    "with open(input_filename) as inf:\n",
    "    for line in inf:\n",
    "        if len(line.strip()) == 0: \n",
    "            continue\n",
    "        tweets.append(json.loads(line)['id'])\n",
    "len(tweets)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(labels_filename) as inf:\n",
    "    labels = json.load(inf)\n",
    "\n",
    "# Ensure only classified tweets are loaded\n",
    "tweets = tweets[:len(labels)]\n",
    "assert len(tweets) == len(labels)\n",
    "len(labels), len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "pipeline = Pipeline([('bag-of-words', BagOfWords()), ('vectorizer', DictVectorizer()), ('naive-bayes', BernoulliNB()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mytweets=np.array(tweets)\n",
    "mypipe=np.array(pipeline)\n",
    "mylabels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, array([<__main__.BagOfWords object at 0x00000195FFEBC310>,\n       DictVectorizer(), BernoulliNB()], dtype=object) was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaive_bayes\u001b[39;00m \u001b[39mimport\u001b[39;00m BernoulliNB\n\u001b[1;32m----> 3\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(mypipe, mytweets, mylabels, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39mmean(scores)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:513\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluate a score by cross-validation.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \n\u001b[0;32m    397\u001b[0m \u001b[39mRead more in the :ref:`User Guide <cross_validation>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m[0.3315057  0.08022103 0.03531816]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39;49mscoring)\n\u001b[0;32m    515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py:474\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determine scorer from user options.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[39mA TypeError will be thrown if the estimator cannot be scored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[39m    ``scorer(estimator, X, y)``.\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 474\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    475\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mestimator should be an estimator implementing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method, \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m was passed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    476\u001b[0m         \u001b[39m%\u001b[39m estimator\n\u001b[0;32m    477\u001b[0m     )\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scoring, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m get_scorer(scoring)\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, array([<__main__.BagOfWords object at 0x00000195FFEBC310>,\n       DictVectorizer(), BernoulliNB()], dtype=object) was passed"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "scores = cross_val_score(mypipe, mytweets, mylabels, scoring='f1')\n",
    "import numpy as np\n",
    "print(\"Score: {:.3f}\".format(np.mean(scores)))\n",
    "#We then print out the average of the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Language.__call__() got an unexpected keyword argument 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit(tweets, labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mBagOfWords.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m document \u001b[39min\u001b[39;00m X:\n\u001b[0;32m     15\u001b[0m     row \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(nlp(document, tag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, parse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, entity\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)):\n\u001b[0;32m     17\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(word\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()):\n\u001b[0;32m     18\u001b[0m             row[word\u001b[39m.\u001b[39mtext] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Language.__call__() got an unexpected keyword argument 'tag'"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(tweets, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nb \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mnaive-bayes\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m feature_probabilities \u001b[39m=\u001b[39m nb\u001b[39m.\u001b[39mfeature_log_prob_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "nb = model.named_steps['naive-bayes']\n",
    "feature_probabilities = nb.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(\u001b[39m-\u001b[39mnb\u001b[39m.\u001b[39mfeature_log_prob_[\u001b[39m1\u001b[39m])[:\u001b[39m50\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nb' is not defined"
     ]
    }
   ],
   "source": [
    "top_features = np.argsort(-nb.feature_log_prob_[1])[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dv \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mvectorizer\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "dv = model.named_steps['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, feature_index \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(top_features):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(i, dv\u001b[39m.\u001b[39mfeature_names_[feature_index], np\u001b[39m.\u001b[39mexp(feature_probabilities[\u001b[39m1\u001b[39m][feature_index]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_features' is not defined"
     ]
    }
   ],
   "source": [
    "for i, feature_index in enumerate(top_features):\n",
    "    print(i, dv.feature_names_[feature_index], np.exp(feature_probabilities[1][feature_index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
